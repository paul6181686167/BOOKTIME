#!/usr/bin/env python3
"""
üìä MONITORING ULTRA HARVEST PRODUCTION
Script de surveillance et validation des ex√©cutions Ultra Harvest automatiques
"""

import json
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
import logging
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/app/logs/ultra_harvest_monitoring.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class UltraHarvestMonitor:
    """Monitoring et validation Ultra Harvest production"""
    
    def __init__(self):
        self.db_path = Path('/app/data/ultra_harvest_tracking.db')
        self.logs_dir = Path('/app/logs')
        self.sessions_file = Path('/app/data/ultra_harvest_sessions.json')
        
    def check_database_health(self):
        """V√©rification sant√© base de donn√©es tracking"""
        try:
            if not self.db_path.exists():
                logger.warning("‚ö†Ô∏è Base donn√©es tracking introuvable")
                return {
                    'status': 'warning',
                    'message': 'Base donn√©es tracking non initialis√©e',
                    'recommendations': ['Lancer Ultra Harvest pour initialiser']
                }
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT 
                        COUNT(*) as total_books,
                        COUNT(CASE WHEN series_detected = 1 THEN 1 END) as series_found,
                        MAX(analysis_date) as last_analysis
                    FROM analyzed_books
                """)
                
                result = cursor.fetchone()
                total_books, series_found, last_analysis = result
                
                detection_rate = (series_found / total_books * 100) if total_books > 0 else 0
                
                # Analyse temporelle
                if last_analysis:
                    last_date = datetime.fromisoformat(last_analysis.replace('Z', '+00:00').replace('+00:00', ''))
                    days_since = (datetime.now() - last_date).days
                else:
                    days_since = float('inf')
                
                # D√©termination statut
                if days_since > 10:
                    status = 'error'
                    message = f"Aucune analyse depuis {days_since} jours"
                elif days_since > 7:
                    status = 'warning' 
                    message = f"Derni√®re analyse il y a {days_since} jours"
                elif detection_rate < 1:
                    status = 'warning'
                    message = f"Taux d√©tection tr√®s bas: {detection_rate:.1f}%"
                else:
                    status = 'success'
                    message = "Base donn√©es saine"
                
                return {
                    'status': status,
                    'message': message,
                    'metrics': {
                        'total_books': total_books,
                        'series_found': series_found, 
                        'detection_rate': detection_rate,
                        'days_since_last': days_since,
                        'last_analysis': last_analysis
                    }
                }
                
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification DB: {e}")
            return {
                'status': 'error',
                'message': f'Erreur base donn√©es: {str(e)}',
                'recommendations': ['V√©rifier int√©grit√© base donn√©es']
            }
    
    def check_recent_logs(self):
        """Analyse logs r√©cents pour d√©tecter probl√®mes"""
        try:
            # Chercher logs Ultra Harvest r√©cents (7 derniers jours)
            recent_logs = []
            for log_file in self.logs_dir.glob("ultra_harvest_weekly_*.log"):
                if log_file.stat().st_mtime > (datetime.now() - timedelta(days=7)).timestamp():
                    recent_logs.append(log_file)
            
            if not recent_logs:
                return {
                    'status': 'warning',
                    'message': 'Aucun log Ultra Harvest r√©cent trouv√©',
                    'recommendations': ['V√©rifier ex√©cution cron job']
                }
            
            # Analyse du log le plus r√©cent
            latest_log = max(recent_logs, key=lambda f: f.stat().st_mtime)
            
            with open(latest_log, 'r') as f:
                log_content = f.read()
            
            # Recherche patterns succ√®s/√©chec
            success_patterns = [
                "‚úÖ ULTRA HARVEST R√âUSSI",
                "ULTRA HARVEST 100K TERMIN√â",
                "success: True"
            ]
            
            error_patterns = [
                "‚ùå ERREUR",
                "ERROR",
                "FAILED",
                "Exception",
                "success: False"
            ]
            
            has_success = any(pattern in log_content for pattern in success_patterns)
            has_errors = any(pattern in log_content for pattern in error_patterns)
            
            if has_success and not has_errors:
                status = 'success'
                message = f"Derni√®re ex√©cution r√©ussie ({latest_log.name})"
            elif has_errors:
                status = 'error'
                message = f"Erreurs d√©tect√©es dans {latest_log.name}"
            else:
                status = 'warning'
                message = f"Statut ex√©cution unclear dans {latest_log.name}"
            
            return {
                'status': status,
                'message': message,
                'latest_log': str(latest_log),
                'log_analysis': {
                    'has_success_indicators': has_success,
                    'has_error_indicators': has_errors,
                    'log_size_kb': latest_log.stat().st_size // 1024
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur analyse logs: {e}")
            return {
                'status': 'error',
                'message': f'Erreur analyse logs: {str(e)}'
            }
    
    def check_cron_schedule(self):
        """V√©rification configuration cron (approximative)"""
        try:
            # V√©rifier si script weekly existe et est ex√©cutable
            weekly_script = Path('/app/scripts/weekly_ultra_harvest.sh')
            
            if not weekly_script.exists():
                return {
                    'status': 'error',
                    'message': 'Script weekly Ultra Harvest introuvable',
                    'recommendations': ['Installer script weekly_ultra_harvest.sh']
                }
            
            if not weekly_script.stat().st_mode & 0o111:
                return {
                    'status': 'warning', 
                    'message': 'Script weekly non ex√©cutable',
                    'recommendations': ['chmod +x /app/scripts/weekly_ultra_harvest.sh']
                }
            
            return {
                'status': 'success',
                'message': 'Script weekly disponible et ex√©cutable',
                'script_path': str(weekly_script)
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'message': f'Erreur v√©rification cron: {str(e)}'
            }
    
    def generate_weekly_report(self):
        """G√©n√©ration rapport hebdomadaire complet"""
        logger.info("üìä G√©n√©ration rapport monitoring Ultra Harvest")
        
        # Collecte toutes les v√©rifications
        db_check = self.check_database_health()
        logs_check = self.check_recent_logs()
        cron_check = self.check_cron_schedule()
        
        # Statut global
        all_statuses = [db_check['status'], logs_check['status'], cron_check['status']]
        
        if 'error' in all_statuses:
            global_status = 'error'
        elif 'warning' in all_statuses:
            global_status = 'warning'
        else:
            global_status = 'success'
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'global_status': global_status,
            'checks': {
                'database': db_check,
                'logs': logs_check,
                'cron': cron_check
            },
            'summary': {
                'total_books_analyzed': db_check.get('metrics', {}).get('total_books', 0),
                'total_series_found': db_check.get('metrics', {}).get('series_found', 0),
                'detection_rate': db_check.get('metrics', {}).get('detection_rate', 0),
                'days_since_last_run': db_check.get('metrics', {}).get('days_since_last', 0)
            }
        }
        
        # Sauvegarde rapport
        report_file = Path(f'/app/logs/ultra_harvest_weekly_report_{datetime.now().strftime("%Y%m%d")}.json')
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        # Affichage console
        self._print_report(report)
        
        return report
    
    def _print_report(self, report):
        """Affichage rapport format√©"""
        status_emoji = {
            'success': '‚úÖ',
            'warning': '‚ö†Ô∏è', 
            'error': '‚ùå'
        }
        
        global_emoji = status_emoji.get(report['global_status'], '‚ùì')
        
        print(f"""
üìä RAPPORT MONITORING ULTRA HARVEST PRODUCTION
=============================================
{global_emoji} Statut Global: {report['global_status'].upper()}
üìÖ Timestamp: {report['timestamp']}

üóÑÔ∏è Base de Donn√©es:
   {status_emoji.get(report['checks']['database']['status'], '‚ùì')} {report['checks']['database']['message']}
   üìö Livres analys√©s: {report['summary']['total_books_analyzed']:,}
   üéØ S√©ries trouv√©es: {report['summary']['total_series_found']:,} 
   üìà Taux d√©tection: {report['summary']['detection_rate']:.1f}%

üìã Logs d'Ex√©cution:
   {status_emoji.get(report['checks']['logs']['status'], '‚ùì')} {report['checks']['logs']['message']}

‚è∞ Configuration Cron:
   {status_emoji.get(report['checks']['cron']['status'], '‚ùì')} {report['checks']['cron']['message']}

üìä R√âSUM√â:
   üìÖ Derni√®re ex√©cution: {report['summary']['days_since_last_run']} jour(s)
   üìà Performance: {'EXCELLENT' if report['summary']['detection_rate'] > 5 else 'CORRECT' if report['summary']['detection_rate'] > 1 else '√Ä AM√âLIORER'}
   üéØ Recommandation: {'Fonctionnement optimal' if report['global_status'] == 'success' else 'V√©rifications requises'}
=============================================
""")

def main():
    """Point d'entr√©e monitoring"""
    monitor = UltraHarvestMonitor()
    
    try:
        report = monitor.generate_weekly_report()
        
        # Exit code bas√© sur statut global
        exit_codes = {
            'success': 0,
            'warning': 1,
            'error': 2
        }
        
        exit_code = exit_codes.get(report['global_status'], 3)
        
        if exit_code > 0:
            logger.warning(f"‚ö†Ô∏è Monitoring d√©tect√© probl√®mes (exit code: {exit_code})")
        else:
            logger.info("‚úÖ Monitoring Ultra Harvest: Tout OK")
        
        return exit_code
        
    except Exception as e:
        logger.error(f"‚ùå Erreur monitoring: {e}")
        return 3

if __name__ == "__main__":
    exit(main())