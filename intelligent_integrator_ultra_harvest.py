#!/usr/bin/env python3
"""
ğŸ”„ INTÃ‰GRATEUR INTELLIGENT ULTRA HARVEST â†’ BOOKTIME
Ajoute automatiquement les nouvelles sÃ©ries de qualitÃ© Ã  BookTime
"""

import sqlite3
import json
import os
import time
from datetime import datetime
from collections import defaultdict

def load_booktime_series():
    """Charge la base BookTime actuelle"""
    series_file = "/app/backend/data/extended_series_database.json"
    
    if os.path.exists(series_file):
        with open(series_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

def get_ultra_harvest_candidates():
    """RÃ©cupÃ¨re les meilleures candidates Ultra Harvest"""
    
    db_file = "/app/data/ultra_harvest_tracking.db"
    
    if not os.path.exists(db_file):
        return []
    
    conn = sqlite3.connect(db_file)
    cursor = conn.cursor()
    
    # CritÃ¨res plus permissifs pour voir plus de rÃ©sultats
    cursor.execute("""
        SELECT series_name, COUNT(*) as volume_count,
               AVG(confidence_score) as avg_confidence,
               GROUP_CONCAT(DISTINCT author) as authors,
               MAX(title) as sample_title
        FROM analyzed_books 
        WHERE series_detected = 1 
          AND series_name IS NOT NULL 
          AND confidence_score > 60
        GROUP BY series_name
        HAVING COUNT(*) >= 2
        ORDER BY AVG(confidence_score) DESC, COUNT(*) DESC
        LIMIT 100
    """)
    
    candidates = []
    for row in cursor.fetchall():
        series_name, volume_count, avg_confidence, authors, sample_title = row
        
        # Nettoyer le nom
        clean_name = series_name.strip()
        if len(clean_name) < 3:
            continue
        
        # DÃ©terminer la catÃ©gorie
        category = "roman"  # Par dÃ©faut
        name_lower = clean_name.lower()
        sample_lower = (sample_title or "").lower()
        
        # DÃ©tection manga
        if any(word in name_lower or word in sample_lower for word in [
            "manga", "naruto", "bleach", "one piece", "dragon ball", "fullmetal alchemist",
            "death note", "attack on titan", "demon slayer", "my hero academia"
        ]):
            category = "manga"
        
        # DÃ©tection BD
        elif any(word in name_lower or word in sample_lower for word in [
            "tintin", "asterix", "gaston", "spirou", "bd", "comic", "bande dessinee"
        ]):
            category = "bd"
        
        candidate = {
            "name": clean_name,
            "category": category,
            "score": int(avg_confidence),
            "keywords": [clean_name.lower()],
            "authors": [authors.split(",")[0].strip()] if authors else [],
            "variations": [clean_name],
            "volumes": volume_count,
            "languages": ["fr", "en"],
            "description": f"SÃ©rie dÃ©tectÃ©e par Ultra Harvest avec {volume_count} volumes",
            "first_published": 2000,
            "status": "ongoing",
            "source": "ultra_harvest_100k_intelligent",
            "detection_date": datetime.now().isoformat(),
            "ultra_harvest_confidence": avg_confidence,
            "sample_title": sample_title
        }
        
        candidates.append(candidate)
    
    conn.close()
    return candidates

def filter_quality_series(candidates, existing_series):
    """Filtre les sÃ©ries de haute qualitÃ© vraiment nouvelles"""
    
    existing_names = {s.get("name", "").lower().strip() for s in existing_series}
    quality_series = []
    
    for candidate in candidates:
        name = candidate["name"]
        name_lower = name.lower()
        
        # DÃ©jÃ  existe ?
        if name_lower in existing_names:
            continue
        
        # Filtres qualitÃ© stricts
        
        # 1. Exclure termes problÃ©matiques
        problematic_terms = [
            "student edition", "teacher", "textbook", "manual", "guide", 
            "handbook", "cookbook", "academic", "university", "collection",
            "anthology", "best of", "selected works", "complete", "integral"
        ]
        
        if any(term in name_lower for term in problematic_terms):
            continue
        
        # 2. Minimum qualitÃ©
        if candidate["score"] < 75 or candidate["volumes"] < 3:
            continue
        
        # 3. Longueur nom raisonnable
        if len(name) < 3 or len(name) > 50:
            continue
        
        # 4. Ã‰viter noms trop gÃ©nÃ©riques
        generic_terms = ["book", "tome", "volume", "part", "chapter", "episode"]
        if name_lower in generic_terms:
            continue
        
        quality_series.append(candidate)
    
    return quality_series

def integrate_series_to_booktime(new_series):
    """IntÃ¨gre les nouvelles sÃ©ries dans BookTime"""
    
    if not new_series:
        return 0
    
    # Backup base actuelle
    series_file = "/app/backend/data/extended_series_database.json"
    backup_file = f"/app/backend/data/extended_series_database_backup_ultra_harvest_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    existing_series = load_booktime_series()
    
    # Sauvegarde
    with open(backup_file, 'w', encoding='utf-8') as f:
        json.dump(existing_series, f, ensure_ascii=False, indent=2)
    
    # Ajouter nouvelles sÃ©ries
    updated_series = existing_series + new_series
    
    # Sauvegarder
    with open(series_file, 'w', encoding='utf-8') as f:
        json.dump(updated_series, f, ensure_ascii=False, indent=2)
    
    return len(new_series)

def display_integration_status():
    """Affiche le statut d'intÃ©gration"""
    
    print(f"ğŸ”„ INTÃ‰GRATION ULTRA HARVEST â†’ BOOKTIME")
    print(f"{'='*55}")
    print(f"ğŸ•’ {datetime.now().strftime('%H:%M:%S')}")
    
    # Charger base actuelle
    existing_series = load_booktime_series()
    print(f"ğŸ“š Base BookTime actuelle: {len(existing_series):,} sÃ©ries")
    
    # Analyser candidates Ultra Harvest
    candidates = get_ultra_harvest_candidates()
    print(f"ğŸ” Candidates Ultra Harvest: {len(candidates)} sÃ©ries")
    
    # Filtrer qualitÃ©
    quality_series = filter_quality_series(candidates, existing_series)
    print(f"âœ¨ SÃ©ries qualitÃ© Ã  ajouter: {len(quality_series)}")
    
    if quality_series:
        print(f"\nğŸ¯ NOUVELLES SÃ‰RIES DE QUALITÃ‰:")
        for i, serie in enumerate(quality_series[:10], 1):
            print(f"  {i:2d}. {serie['name'][:35]:<35} | {serie['category']:<6} | {serie['volumes']:2d} vol | {serie['score']:2d}%")
        
        if len(quality_series) > 10:
            print(f"     ... et {len(quality_series) - 10} autres sÃ©ries de qualitÃ©")
        
        # IntÃ©grer
        integrated = integrate_series_to_booktime(quality_series)
        print(f"\nâœ… {integrated} nouvelles sÃ©ries intÃ©grÃ©es Ã  BookTime!")
        print(f"ğŸ“Š Total sÃ©ries BookTime: {len(existing_series) + integrated:,}")
        
        return integrated
    else:
        print("\nâ„¹ï¸ Aucune nouvelle sÃ©rie de qualitÃ© suffisante trouvÃ©e")
        return 0

def main():
    """IntÃ©gration continue avec affichage dÃ©taillÃ©"""
    
    print("ğŸš€ DÃ‰MARRAGE INTÃ‰GRATEUR INTELLIGENT ULTRA HARVEST")
    print("=" * 60)
    
    total_integrated = 0
    
    try:
        while True:
            new_count = display_integration_status()
            total_integrated += new_count
            
            print(f"\nğŸ’« Total intÃ©grÃ© cette session: {total_integrated} sÃ©ries")
            print("-" * 60)
            
            # Attendre 3 minutes
            time.sleep(180)
            
    except KeyboardInterrupt:
        print(f"\nğŸ‘‹ IntÃ©grateur arrÃªtÃ©")
        print(f"ğŸ“Š Total intÃ©grÃ©: {total_integrated} nouvelles sÃ©ries")

if __name__ == "__main__":
    # ExÃ©cution unique pour voir l'Ã©tat
    display_integration_status()