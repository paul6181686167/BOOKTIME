#!/usr/bin/env python3
"""
üöÄ WIKIPEDIA SERIES ENRICHER V2.0 - D√©tection Am√©lior√©e
Patterns sp√©cialis√©s pour s√©ries populaires + validation renforc√©e
"""

import asyncio
import aiohttp
import re
import json
from datetime import datetime
from typing import List, Dict, Optional, Tuple
import logging

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class WikipediaSeriesEnricherV2:
    """Version am√©lior√©e avec patterns sp√©cialis√©s"""
    
    def __init__(self):
        self.session = None
        self.base_url = "https://en.wikipedia.org/api/rest_v1/page/summary/"
        self.series_detected = []
        self.authors_processed = []
        
        # S√©ries connues pour validation
        self.known_series = {
            'Harry Potter', 'The Dark Tower', 'Discworld', 'Wheel of Time',
            'A Song of Ice and Fire', 'The Hunger Games', 'Percy Jackson',
            'The Mortal Instruments', 'Dune', 'Foundation', 'Earthsea',
            'The Chronicles of Narnia', 'His Dark Materials', 'The Dresden Files',
            'The Witcher', 'Mistborn', 'The Stormlight Archive', 'The Expanse',
            'The Southern Reach', 'The Kingkiller Chronicle', 'The First Law',
            'The Malazan Book of the Fallen', 'The Gentleman Bastard',
            'The Broken Empire', 'The Farseer Trilogy', 'The Culture',
            'Hyperion Cantos', 'The Imperial Radch', 'The Wayfarers',
            'The Expanse', 'The Locked Tomb', 'The Poppy War'
        }
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def get_author_wikipedia_page(self, author_name: str) -> Optional[Dict]:
        """R√©cup√®re la page Wikipedia d'un auteur"""
        try:
            formatted_name = author_name.replace(' ', '_')
            url = f"{self.base_url}{formatted_name}"
            
            logger.info(f"üîç Recherche Wikipedia pour : {author_name}")
            
            async with self.session.get(url) as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"‚úÖ Page Wikipedia trouv√©e : {author_name}")
                    return data
                else:
                    logger.warning(f"‚ùå Pas de page Wikipedia : {author_name}")
                    return None
                    
        except Exception as e:
            logger.error(f"‚ùå Erreur Wikipedia {author_name}: {str(e)}")
            return None
    
    def extract_series_with_improved_patterns(self, description: str, author_name: str) -> List[Dict]:
        """Extraction am√©lior√©e avec patterns sp√©cialis√©s"""
        series_found = []
        
        # Patterns sp√©cialis√©s pour diff√©rents types de s√©ries
        improved_patterns = [
            # Pattern pour s√©ries explicites
            (r'(?:author|creator|writer) of (?:the )?([A-Z][a-zA-Z\s]+?) (?:series|saga|cycle)', 90),
            (r'(?:wrote|created|best known for) (?:the )?([A-Z][a-zA-Z\s]+?) (?:series|novels|books)', 85),
            (r'(?:the )?([A-Z][a-zA-Z\s]+?) (?:fantasy|science fiction|mystery|horror) series', 85),
            
            # Patterns pour s√©ries connues
            (r'(Harry Potter)', 95),
            (r'(The Dark Tower)', 95),
            (r'(Discworld)', 95),
            (r'(Wheel of Time)', 95),
            (r'(A Song of Ice and Fire)', 95),
            (r'(The Hunger Games)', 95),
            (r'(Percy Jackson)', 95),
            (r'(The Mortal Instruments)', 95),
            (r'(Foundation)', 95),
            (r'(Dune)', 95),
            (r'(Earthsea)', 95),
            (r'(The Dresden Files)', 95),
            (r'(Mistborn)', 95),
            (r'(The Stormlight Archive)', 95),
            
            # Patterns pour volumes multiples
            (r'([A-Z][a-zA-Z\s]+?) (?:trilogy|tetralogy|pentalogy)', 80),
            (r'([A-Z][a-zA-Z\s]+?) (?:book series|novel series)', 80),
            (r'([A-Z][a-zA-Z\s]+?) (?:seven|six|five|four|three) (?:books|novels|volumes)', 75),
        ]
        
        logger.info(f"üîç Analyse am√©lior√©e pour : {author_name}")
        
        for pattern, confidence in improved_patterns:
            matches = re.findall(pattern, description, re.IGNORECASE)
            for match in matches:
                series_name = match.strip()
                
                # Validation renforc√©e
                if self.is_valid_series_name_v2(series_name):
                    series_info = {
                        'name': series_name,
                        'author': author_name,
                        'source': 'wikipedia_improved',
                        'detected_at': datetime.now().isoformat(),
                        'confidence': confidence,
                        'validation_passed': True
                    }
                    
                    # V√©rifier si d√©j√† d√©tect√©
                    if not self.is_duplicate_series(series_info):
                        series_found.append(series_info)
                        logger.info(f"üìö S√©rie valid√©e : {series_name} par {author_name} (conf: {confidence}%)")
        
        return series_found
    
    def is_valid_series_name_v2(self, name: str) -> bool:
        """Validation renforc√©e des noms de s√©ries"""
        # Filtres n√©gatifs
        invalid_keywords = [
            'literature', 'fiction', 'books', 'novels', 'works', 'writing',
            'style', 'genre', 'career', 'life', 'biography', 'awards',
            'university', 'college', 'school', 'education', 'degree',
            'her', 'his', 'and', 'the author', 'bestselling', 'award',
            'children', 'young adult', 'dystopian', 'horror', 'fantasy',
            'science fiction', 'mystery', 'graphic', 'unfinished'
        ]
        
        name_lower = name.lower().strip()
        
        # V√©rifications de base
        if len(name) < 3 or len(name) > 60:
            return False
            
        # Filtrage des mots-cl√©s invalides
        if any(keyword in name_lower for keyword in invalid_keywords):
            return False
            
        # Doit contenir des lettres
        if not re.search(r'[a-zA-Z]', name):
            return False
            
        # Filtrage des fragments
        if name_lower.startswith(('a ', 'an ', 'the ', 'and ', 'her ', 'his ')):
            return False
            
        # V√©rification s√©ries connues (boost de confiance)
        if any(known.lower() in name_lower for known in self.known_series):
            return True
            
        # Doit ressembler √† un titre
        if re.match(r'^[A-Z][a-zA-Z\s]+$', name):
            return True
            
        return False
    
    def is_duplicate_series(self, series_info: Dict) -> bool:
        """V√©rifie les doublons"""
        for existing in self.series_detected:
            if (existing['name'].lower() == series_info['name'].lower() and 
                existing['author'] == series_info['author']):
                return True
        return False
    
    def get_fantasy_scifi_authors(self) -> List[str]:
        """Auteurs sp√©cialis√©s fantasy/sci-fi avec s√©ries connues"""
        return [
            "J.K. Rowling",          # Harry Potter
            "Stephen King",          # The Dark Tower
            "Terry Pratchett",       # Discworld
            "George R.R. Martin",    # A Song of Ice and Fire
            "Robert Jordan",         # Wheel of Time
            "Brandon Sanderson",     # Mistborn, Stormlight Archive
            "Jim Butcher",           # The Dresden Files
            "Rick Riordan",          # Percy Jackson
            "Suzanne Collins",       # The Hunger Games
            "Cassandra Clare",       # The Mortal Instruments
            "Frank Herbert",         # Dune
            "Isaac Asimov",          # Foundation
            "Ursula K. Le Guin",     # Earthsea
            "Douglas Adams",         # Hitchhiker's Guide
            "Neil Gaiman",           # Various series
            "Orson Scott Card",      # Ender's Game
            "Philip K. Dick",        # Various series
            "Arthur C. Clarke",      # Various series
            "Ray Bradbury",          # Various series
            "Agatha Christie",       # Poirot, Miss Marple
            "James S.A. Corey",      # The Expanse
            "Robin Hobb",            # Farseer Trilogy
            "Joe Abercrombie",       # The First Law
            "Patrick Rothfuss",      # The Kingkiller Chronicle
            "Scott Lynch",           # Gentleman Bastard
            "Mark Lawrence",         # The Broken Empire
            "N.K. Jemisin",          # The Broken Earth
            "Becky Chambers",        # Wayfarers
            "Martha Wells",          # The Murderbot Diaries
            "Jeff VanderMeer",       # Southern Reach
        ]
    
    async def enrich_series_for_author(self, author_name: str) -> List[Dict]:
        """Enrichit les s√©ries pour un auteur donn√©"""
        logger.info(f"üöÄ Enrichissement am√©lior√© pour : {author_name}")
        
        # R√©cup√©ration page Wikipedia
        wiki_page = await self.get_author_wikipedia_page(author_name)
        if not wiki_page:
            return []
        
        # Extraction des s√©ries
        description = wiki_page.get('extract', '')
        if not description:
            logger.warning(f"‚ùå Pas de description pour : {author_name}")
            return []
        
        series_found = self.extract_series_with_improved_patterns(description, author_name)
        
        # Ajout √† la liste globale
        self.series_detected.extend(series_found)
        self.authors_processed.append(author_name)
        
        logger.info(f"‚úÖ {len(series_found)} s√©ries valid√©es pour {author_name}")
        return series_found
    
    async def process_all_authors(self, authors: List[str]) -> Dict:
        """Traite tous les auteurs en parall√®le"""
        logger.info(f"üöÄ D√©marrage enrichissement am√©lior√© pour {len(authors)} auteurs")
        
        # Traitement parall√®le avec limitation
        semaphore = asyncio.Semaphore(3)  # Max 3 requ√™tes simultan√©es
        
        async def process_author_with_semaphore(author):
            async with semaphore:
                return await self.enrich_series_for_author(author)
        
        # Ex√©cution parall√®le
        results = await asyncio.gather(
            *[process_author_with_semaphore(author) for author in authors],
            return_exceptions=True
        )
        
        # Tri par confiance
        self.series_detected.sort(key=lambda x: x['confidence'], reverse=True)
        
        # Statistiques finales
        total_series = len(self.series_detected)
        total_authors = len(self.authors_processed)
        high_confidence = len([s for s in self.series_detected if s['confidence'] >= 85])
        
        logger.info(f"üéØ ENRICHISSEMENT AM√âLIOR√â TERMIN√â :")
        logger.info(f"   üìö {total_series} s√©ries d√©tect√©es")
        logger.info(f"   üéØ {high_confidence} s√©ries haute confiance (‚â•85%)")
        logger.info(f"   üë§ {total_authors} auteurs trait√©s")
        
        return {
            'total_series_detected': total_series,
            'high_confidence_series': high_confidence,
            'total_authors_processed': total_authors,
            'series_detected': self.series_detected,
            'authors_processed': self.authors_processed,
            'enrichment_completed_at': datetime.now().isoformat(),
            'version': '2.0'
        }
    
    def save_results(self, results: Dict, filename: str = "wikipedia_series_enrichment_v2.json"):
        """Sauvegarde les r√©sultats"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            logger.info(f"üíæ R√©sultats sauvegard√©s : {filename}")
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde : {str(e)}")

async def main():
    """Fonction principale d'enrichissement am√©lior√©"""
    logger.info("üöÄ D√âMARRAGE WIKIPEDIA SERIES ENRICHER V2.0")
    
    async with WikipediaSeriesEnricherV2() as enricher:
        # R√©cup√©ration des auteurs sp√©cialis√©s
        authors = enricher.get_fantasy_scifi_authors()
        
        # Traitement de tous les auteurs
        results = await enricher.process_all_authors(authors)
        
        # Sauvegarde des r√©sultats
        enricher.save_results(results)
        
        # Affichage r√©sum√©
        print("\nüéØ R√âSUM√â ENRICHISSEMENT WIKIP√âDIA V2.0 :")
        print(f"üìö S√©ries d√©tect√©es : {results['total_series_detected']}")
        print(f"üéØ Haute confiance : {results['high_confidence_series']} (‚â•85%)")
        print(f"üë§ Auteurs trait√©s : {results['total_authors_processed']}")
        print(f"üìä Taux succ√®s : {results['total_authors_processed']}/{len(authors)} auteurs")
        
        # Affichage des s√©ries haute confiance
        print("\nüìö S√âRIES HAUTE CONFIANCE D√âTECT√âES :")
        high_conf_series = [s for s in results['series_detected'] if s['confidence'] >= 85]
        for series in high_conf_series[:15]:  # Affiche les 15 premi√®res
            print(f"   ‚Ä¢ {series['name']} - {series['author']} ({series['confidence']}%)")
        
        if len(high_conf_series) > 15:
            print(f"   ... et {len(high_conf_series) - 15} autres")

if __name__ == "__main__":
    asyncio.run(main())