#!/usr/bin/env python3
"""
üîÑ MISE √Ä JOUR SYST√àME D√âTECTION S√âRIES
Integration des nouvelles s√©ries Open Library dans le syst√®me de d√©tection BOOKTIME

Fonctionnalit√©s :
- Chargement des nouvelles s√©ries depuis la base de donn√©es
- Mise √† jour du fichier EXTENDED_SERIES_DATABASE JavaScript
- Synchronisation avec le syst√®me de d√©tection frontend
- Validation et tests de coh√©rence
- Backup automatique avant mise √† jour

Utilisation :
python update_series_detection.py
python update_series_detection.py --backup-only
python update_series_detection.py --validate
"""

import json
import shutil
from pathlib import Path
from datetime import datetime
import argparse
import logging
from typing import List, Dict, Set

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SeriesDetectionUpdater:
    """Mise √† jour syst√®me de d√©tection s√©ries"""
    
    def __init__(self):
        self.data_dir = Path('/app/backend/data')
        self.frontend_dir = Path('/app/frontend/src/data')
        self.backup_dir = Path('/app/backups/series_detection')
        
        # Fichiers cibles
        self.json_series_file = self.data_dir / 'extended_series_database.json'
        self.js_series_file = self.frontend_dir / 'extendedSeriesDatabase.js'
        
        # Cr√©ation dossiers
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.frontend_dir.mkdir(parents=True, exist_ok=True)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
    
    def create_backup(self) -> bool:
        """Cr√©ation backup avant mise √† jour"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_subdir = self.backup_dir / f"backup_{timestamp}"
            backup_subdir.mkdir(exist_ok=True)
            
            # Backup fichier JSON
            if self.json_series_file.exists():
                shutil.copy2(self.json_series_file, backup_subdir / 'extended_series_database.json')
                logger.info(f"Backup JSON cr√©√©: {backup_subdir}")
            
            # Backup fichier JS
            if self.js_series_file.exists():
                shutil.copy2(self.js_series_file, backup_subdir / 'extendedSeriesDatabase.js')
                logger.info(f"Backup JS cr√©√©: {backup_subdir}")
            
            return True
        
        except Exception as e:
            logger.error(f"Erreur cr√©ation backup: {str(e)}")
            return False
    
    def load_series_data(self) -> List[Dict]:
        """Chargement donn√©es s√©ries depuis JSON"""
        try:
            if not self.json_series_file.exists():
                logger.warning("Fichier s√©ries JSON non trouv√©")
                return []
            
            with open(self.json_series_file, 'r', encoding='utf-8') as f:
                series_data = json.load(f)
            
            logger.info(f"Charg√© {len(series_data)} s√©ries depuis JSON")
            return series_data
        
        except Exception as e:
            logger.error(f"Erreur chargement s√©ries: {str(e)}")
            return []
    
    def validate_series_data(self, series_data: List[Dict]) -> bool:
        """Validation structure des donn√©es s√©ries"""
        required_fields = ['name', 'authors', 'category', 'volumes', 'keywords', 'variations']
        
        for i, series in enumerate(series_data):
            # V√©rification champs requis
            for field in required_fields:
                if field not in series:
                    logger.error(f"S√©rie {i}: Champ manquant '{field}'")
                    return False
            
            # Validation types
            if not isinstance(series['name'], str) or not series['name'].strip():
                logger.error(f"S√©rie {i}: Nom invalide")
                return False
            
            if not isinstance(series['authors'], list) or not series['authors']:
                logger.error(f"S√©rie {i}: Auteurs invalides")
                return False
            
            if series['category'] not in ['roman', 'bd', 'manga']:
                logger.error(f"S√©rie {i}: Cat√©gorie invalide '{series['category']}'")
                return False
            
            if not isinstance(series['volumes'], int) or series['volumes'] < 1:
                logger.error(f"S√©rie {i}: Nombre de volumes invalide")
                return False
        
        logger.info(f"Validation r√©ussie pour {len(series_data)} s√©ries")
        return True
    
    def deduplicate_series(self, series_data: List[Dict]) -> List[Dict]:
        """D√©duplication des s√©ries par nom"""
        seen_names = set()
        deduplicated = []
        duplicates_count = 0
        
        for series in series_data:
            name_key = series['name'].lower().strip()
            
            if name_key not in seen_names:
                seen_names.add(name_key)
                deduplicated.append(series)
            else:
                duplicates_count += 1
                logger.debug(f"Doublon ignor√©: {series['name']}")
        
        logger.info(f"D√©duplication: {duplicates_count} doublons supprim√©s, {len(deduplicated)} s√©ries uniques")
        return deduplicated
    
    def sort_series_data(self, series_data: List[Dict]) -> List[Dict]:
        """Tri des s√©ries par cat√©gorie puis par nom"""
        def sort_key(series):
            category_order = {'roman': 0, 'bd': 1, 'manga': 2}
            return (category_order.get(series['category'], 3), series['name'].lower())
        
        return sorted(series_data, key=sort_key)
    
    def generate_js_content(self, series_data: List[Dict]) -> str:
        """G√©n√©ration contenu JavaScript pour le frontend"""
        
        # En-t√™te du fichier
        js_content = f"""/**
 * üöÄ EXTENDED SERIES DATABASE - BOOKTIME
 * Base de donn√©es √©tendue des s√©ries populaires
 * 
 * Derni√®re mise √† jour: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
 * Nombre de s√©ries: {len(series_data)}
 * 
 * G√©n√©r√© automatiquement par: update_series_detection.py
 * Source: Open Library + base manuelle
 */

// Export pour modules ES6
export const EXTENDED_SERIES_DATABASE = [
"""
        
        # G√©n√©ration des entr√©es
        for i, series in enumerate(series_data):
            js_content += "  {\n"
            js_content += f"    name: {json.dumps(series['name'], ensure_ascii=False)},\n"
            js_content += f"    authors: {json.dumps(series['authors'], ensure_ascii=False)},\n"
            js_content += f"    category: {json.dumps(series['category'])},\n"
            js_content += f"    volumes: {series['volumes']},\n"
            js_content += f"    keywords: {json.dumps(series['keywords'], ensure_ascii=False)},\n"
            js_content += f"    variations: {json.dumps(series['variations'], ensure_ascii=False)},\n"
            
            # Champs optionnels
            if series.get('first_published'):
                js_content += f"    first_published: {json.dumps(series['first_published'])},\n"
            
            if series.get('status'):
                js_content += f"    status: {json.dumps(series['status'])},\n"
            
            if series.get('description'):
                js_content += f"    description: {json.dumps(series['description'], ensure_ascii=False)},\n"
            
            if series.get('subjects'):
                js_content += f"    subjects: {json.dumps(series['subjects'], ensure_ascii=False)},\n"
            
            if series.get('languages'):
                js_content += f"    languages: {json.dumps(series['languages'])},\n"
            
            if series.get('translations'):
                js_content += f"    translations: {json.dumps(series['translations'], ensure_ascii=False)},\n"
            
            if series.get('source'):
                js_content += f"    source: {json.dumps(series['source'])},\n"
            
            # Fermeture objet
            js_content += "  }"
            
            # Virgule sauf pour le dernier √©l√©ment
            if i < len(series_data) - 1:
                js_content += ","
            
            js_content += "\n"
        
        # Fermeture tableau et statistiques
        js_content += f"""];

// Statistiques base de donn√©es
export const SERIES_STATS = {{
  total_series: {len(series_data)},
  by_category: {{
    roman: {len([s for s in series_data if s['category'] == 'roman'])},
    bd: {len([s for s in series_data if s['category'] == 'bd'])},
    manga: {len([s for s in series_data if s['category'] == 'manga'])}
  }},
  total_volumes: {sum(s['volumes'] for s in series_data)},
  avg_volumes_per_series: {sum(s['volumes'] for s in series_data) / len(series_data):.1f},
  last_updated: "{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}"
}};

// Fonctions utilitaires
export const getSeriesByCategory = (category) => {{
  return EXTENDED_SERIES_DATABASE.filter(series => series.category === category);
}};

export const getSeriesByAuthor = (author) => {{
  return EXTENDED_SERIES_DATABASE.filter(series => 
    series.authors.some(a => a.toLowerCase().includes(author.toLowerCase()))
  );
}};

export const searchSeries = (query) => {{
  const queryLower = query.toLowerCase();
  return EXTENDED_SERIES_DATABASE.filter(series => 
    series.name.toLowerCase().includes(queryLower) ||
    series.authors.some(a => a.toLowerCase().includes(queryLower)) ||
    series.keywords.some(k => k.toLowerCase().includes(queryLower))
  );
}};

// Export par d√©faut
export default EXTENDED_SERIES_DATABASE;
"""
        
        return js_content
    
    def save_js_file(self, js_content: str) -> bool:
        """Sauvegarde fichier JavaScript"""
        try:
            with open(self.js_series_file, 'w', encoding='utf-8') as f:
                f.write(js_content)
            
            logger.info(f"Fichier JS sauvegard√©: {self.js_series_file}")
            return True
        
        except Exception as e:
            logger.error(f"Erreur sauvegarde JS: {str(e)}")
            return False
    
    def update_package_json(self) -> bool:
        """Mise √† jour package.json si n√©cessaire"""
        try:
            package_file = Path('/app/frontend/package.json')
            if not package_file.exists():
                return True
            
            with open(package_file, 'r', encoding='utf-8') as f:
                package_data = json.load(f)
            
            # V√©rification si mise √† jour n√©cessaire
            # (pour l'instant, pas de modifications n√©cessaires)
            
            return True
        
        except Exception as e:
            logger.error(f"Erreur mise √† jour package.json: {str(e)}")
            return False
    
    def run_tests(self, series_data: List[Dict]) -> bool:
        """Tests de coh√©rence des donn√©es"""
        try:
            logger.info("üß™ Ex√©cution tests de coh√©rence")
            
            # Test 1: Unicit√© des noms
            names = [s['name'] for s in series_data]
            if len(names) != len(set(names)):
                logger.error("Test √©chou√©: Noms non uniques")
                return False
            
            # Test 2: Cat√©gories valides
            valid_categories = {'roman', 'bd', 'manga'}
            for series in series_data:
                if series['category'] not in valid_categories:
                    logger.error(f"Test √©chou√©: Cat√©gorie invalide '{series['category']}'")
                    return False
            
            # Test 3: Auteurs non vides
            for series in series_data:
                if not series['authors'] or not all(a.strip() for a in series['authors']):
                    logger.error(f"Test √©chou√©: Auteurs invalides pour '{series['name']}'")
                    return False
            
            # Test 4: Mots-cl√©s coh√©rents
            for series in series_data:
                if len(series['keywords']) == 0:
                    logger.warning(f"Attention: Aucun mot-cl√© pour '{series['name']}'")
            
            # Test 5: Variations coh√©rentes
            for series in series_data:
                if len(series['variations']) == 0:
                    logger.warning(f"Attention: Aucune variation pour '{series['name']}'")
            
            logger.info("‚úÖ Tous les tests de coh√©rence pass√©s")
            return True
        
        except Exception as e:
            logger.error(f"Erreur tests: {str(e)}")
            return False
    
    def generate_report(self, series_data: List[Dict]) -> str:
        """G√©n√©ration rapport de mise √† jour"""
        report = f"""
üîÑ RAPPORT MISE √Ä JOUR SYST√àME D√âTECTION S√âRIES
==============================================

üìä STATISTIQUES GLOBALES
- Nombre total de s√©ries: {len(series_data)}
- R√©partition par cat√©gorie:
  ‚Ä¢ Romans: {len([s for s in series_data if s['category'] == 'roman'])}
  ‚Ä¢ BD: {len([s for s in series_data if s['category'] == 'bd'])}
  ‚Ä¢ Mangas: {len([s for s in series_data if s['category'] == 'manga'])}

üìà M√âTRIQUES CONTENU
- Total volumes: {sum(s['volumes'] for s in series_data)}
- Moyenne volumes/s√©rie: {sum(s['volumes'] for s in series_data) / len(series_data):.1f}
- S√©rie avec le plus de volumes: {max(series_data, key=lambda s: s['volumes'])['name']} ({max(s['volumes'] for s in series_data)} volumes)

üîç MOTS-CL√âS D√âTECTION
- Total mots-cl√©s: {sum(len(s['keywords']) for s in series_data)}
- Moyenne mots-cl√©s/s√©rie: {sum(len(s['keywords']) for s in series_data) / len(series_data):.1f}
- Total variations: {sum(len(s['variations']) for s in series_data)}

üìö TOP 10 S√âRIES PAR VOLUMES
"""
        
        top_series = sorted(series_data, key=lambda s: s['volumes'], reverse=True)[:10]
        for i, series in enumerate(top_series, 1):
            authors = ', '.join(series['authors'][:2])
            report += f"{i}. {series['name']} - {authors} ({series['volumes']} volumes, {series['category']})\n"
        
        report += f"""
üîÑ MISE √Ä JOUR EFFECTU√âE
- Date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- Fichier JS: {self.js_series_file}
- Fichier JSON: {self.json_series_file}
- Backup: {self.backup_dir}

üéØ IMPACT SUR D√âTECTION
- S√©ries automatiquement d√©tect√©es: {len(series_data)}
- Livres individuels potentiellement masqu√©s: Estimation bas√©e sur mots-cl√©s
- Am√©lioration exp√©rience utilisateur: Moins de doublons livre/s√©rie

‚ö° PERFORMANCE ATTENDUE
- D√©tection: <5ms par livre maintenue
- Masquage: Coh√©rent biblioth√®que + recherche
- Cache: Rechargement automatique au red√©marrage

üöÄ PROCHAINES √âTAPES
1. Red√©marrage frontend pour prise en compte
2. Tests fonctionnels masquage intelligent
3. V√©rification d√©tection s√©ries existantes
4. Surveillance logs d√©tection automatique
"""
        
        return report
    
    def run_update(self, backup_only: bool = False, validate_only: bool = False) -> Dict:
        """Ex√©cution mise √† jour compl√®te"""
        
        logger.info("üîÑ D√©marrage mise √† jour syst√®me d√©tection s√©ries")
        
        # Cr√©ation backup
        if not self.create_backup():
            return {'success': False, 'error': '√âchec cr√©ation backup'}
        
        if backup_only:
            logger.info("‚úÖ Backup uniquement - Termin√©")
            return {'success': True, 'message': 'Backup cr√©√© avec succ√®s'}
        
        # Chargement donn√©es
        series_data = self.load_series_data()
        if not series_data:
            return {'success': False, 'error': 'Aucune donn√©e s√©rie trouv√©e'}
        
        # Validation
        if not self.validate_series_data(series_data):
            return {'success': False, 'error': 'Validation des donn√©es √©chou√©e'}
        
        if validate_only:
            logger.info("‚úÖ Validation uniquement - Termin√©")
            return {'success': True, 'message': 'Validation r√©ussie'}
        
        # D√©duplication et tri
        series_data = self.deduplicate_series(series_data)
        series_data = self.sort_series_data(series_data)
        
        # Tests de coh√©rence
        if not self.run_tests(series_data):
            return {'success': False, 'error': 'Tests de coh√©rence √©chou√©s'}
        
        # G√©n√©ration fichier JS
        js_content = self.generate_js_content(series_data)
        if not self.save_js_file(js_content):
            return {'success': False, 'error': '√âchec sauvegarde fichier JS'}
        
        # Mise √† jour package.json
        if not self.update_package_json():
            return {'success': False, 'error': '√âchec mise √† jour package.json'}
        
        # G√©n√©ration rapport
        report = self.generate_report(series_data)
        
        # Sauvegarde rapport
        report_file = Path(f'/app/logs/series_update_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt')
        report_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info("‚úÖ Mise √† jour syst√®me d√©tection termin√©e avec succ√®s")
        
        return {
            'success': True,
            'series_count': len(series_data),
            'js_file': str(self.js_series_file),
            'report_file': str(report_file),
            'backup_dir': str(self.backup_dir)
        }


def main():
    """Fonction principale CLI"""
    parser = argparse.ArgumentParser(description='Mise √† jour syst√®me d√©tection s√©ries')
    parser.add_argument('--backup-only',
                       action='store_true',
                       help='Cr√©er uniquement un backup')
    parser.add_argument('--validate',
                       action='store_true',
                       help='Valider uniquement les donn√©es')
    
    args = parser.parse_args()
    
    # Cr√©ation dossiers
    Path('/app/logs').mkdir(exist_ok=True)
    
    # Ex√©cution mise √† jour
    updater = SeriesDetectionUpdater()
    result = updater.run_update(
        backup_only=args.backup_only,
        validate_only=args.validate
    )
    
    if result['success']:
        print(f"\n‚úÖ MISE √Ä JOUR R√âUSSIE")
        if 'series_count' in result:
            print(f"üìä S√©ries trait√©es: {result['series_count']}")
            print(f"üìÑ Fichier JS: {result['js_file']}")
            print(f"üìã Rapport: {result['report_file']}")
        print(f"üíæ Backup: {result.get('backup_dir', 'Cr√©√©')}")
    else:
        print(f"\n‚ùå ERREUR: {result['error']}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())