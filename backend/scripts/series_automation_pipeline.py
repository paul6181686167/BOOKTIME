#!/usr/bin/env python3
"""
ğŸ¯ ORCHESTRATEUR AUTOMATISATION SÃ‰RIES OPEN LIBRARY
Pipeline complÃ¨te d'automatisation pour BOOKTIME

FonctionnalitÃ©s :
- ExÃ©cution automatique rÃ©cupÃ©ration sÃ©ries Open Library
- Mise Ã  jour systÃ¨me de dÃ©tection
- RedÃ©marrage services si nÃ©cessaire
- Validation end-to-end
- Rapport consolidÃ©

Utilisation :
python series_automation_pipeline.py
python series_automation_pipeline.py --quick --limit=20
python series_automation_pipeline.py --full --limit=100
python series_automation_pipeline.py --test-only
"""

import asyncio
import subprocess
import sys
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List
import argparse

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SeriesAutomationPipeline:
    """Pipeline complÃ¨te d'automatisation sÃ©ries"""
    
    def __init__(self):
        self.scripts_dir = Path('/app/backend/scripts')
        self.logs_dir = Path('/app/logs')
        self.reports_dir = Path('/app/reports')
        
        # CrÃ©ation dossiers
        self.logs_dir.mkdir(exist_ok=True)
        self.reports_dir.mkdir(exist_ok=True)
        
        self.pipeline_stats = {
            'start_time': datetime.now(),
            'steps_completed': 0,
            'total_steps': 5,
            'errors': [],
            'series_added': 0,
            'series_updated': 0
        }
    
    def log_step(self, step_name: str, success: bool, details: str = ""):
        """Logging Ã©tape pipeline"""
        self.pipeline_stats['steps_completed'] += 1
        status = "âœ…" if success else "âŒ"
        
        logger.info(f"{status} [{self.pipeline_stats['steps_completed']}/{self.pipeline_stats['total_steps']}] {step_name}")
        
        if details:
            logger.info(f"   {details}")
        
        if not success:
            self.pipeline_stats['errors'].append(f"{step_name}: {details}")
    
    async def step_1_fetch_series(self, mode: str = 'popular', limit: int = 50) -> Dict:
        """Ã‰tape 1: RÃ©cupÃ©ration sÃ©ries Open Library"""
        logger.info("ğŸ” Ã‰TAPE 1: RÃ©cupÃ©ration sÃ©ries Open Library")
        
        try:
            # ExÃ©cution script rÃ©cupÃ©ration
            cmd = [
                sys.executable,
                str(self.scripts_dir / 'open_library_series_auto.py'),
                '--mode', mode,
                '--limit', str(limit)
            ]
            
            logger.info(f"Commande: {' '.join(cmd)}")
            
            # ExÃ©cution avec capture sortie
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                # Parsing rÃ©sultat depuis stdout
                output = stdout.decode('utf-8')
                
                # Extraction mÃ©triques (parsing basique)
                series_added = 0
                duplicates_skipped = 0
                
                lines = output.split('\n')
                for line in lines:
                    if 'SÃ©ries ajoutÃ©es:' in line:
                        try:
                            series_added = int(line.split(':')[1].strip())
                        except:
                            pass
                    elif 'Doublons ignorÃ©s:' in line:
                        try:
                            duplicates_skipped = int(line.split(':')[1].strip())
                        except:
                            pass
                
                self.pipeline_stats['series_added'] = series_added
                self.log_step("RÃ©cupÃ©ration sÃ©ries Open Library", True, 
                             f"{series_added} sÃ©ries ajoutÃ©es, {duplicates_skipped} doublons ignorÃ©s")
                
                return {
                    'success': True,
                    'series_added': series_added,
                    'duplicates_skipped': duplicates_skipped,
                    'output': output
                }
            
            else:
                error_msg = stderr.decode('utf-8')
                self.log_step("RÃ©cupÃ©ration sÃ©ries Open Library", False, 
                             f"Code erreur: {process.returncode}, {error_msg}")
                
                return {
                    'success': False,
                    'error': error_msg,
                    'return_code': process.returncode
                }
        
        except Exception as e:
            self.log_step("RÃ©cupÃ©ration sÃ©ries Open Library", False, str(e))
            return {'success': False, 'error': str(e)}
    
    def step_2_update_detection(self) -> Dict:
        """Ã‰tape 2: Mise Ã  jour systÃ¨me dÃ©tection"""
        logger.info("ğŸ”„ Ã‰TAPE 2: Mise Ã  jour systÃ¨me dÃ©tection")
        
        try:
            # ExÃ©cution script mise Ã  jour
            cmd = [
                sys.executable,
                str(self.scripts_dir / 'update_series_detection.py')
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300  # 5 minutes timeout
            )
            
            if result.returncode == 0:
                # Parsing rÃ©sultat
                series_count = 0
                lines = result.stdout.split('\n')
                for line in lines:
                    if 'SÃ©ries traitÃ©es:' in line:
                        try:
                            series_count = int(line.split(':')[1].strip())
                        except:
                            pass
                
                self.pipeline_stats['series_updated'] = series_count
                self.log_step("Mise Ã  jour systÃ¨me dÃ©tection", True,
                             f"{series_count} sÃ©ries dans le systÃ¨me")
                
                return {
                    'success': True,
                    'series_count': series_count,
                    'output': result.stdout
                }
            
            else:
                self.log_step("Mise Ã  jour systÃ¨me dÃ©tection", False,
                             f"Code erreur: {result.returncode}, {result.stderr}")
                
                return {
                    'success': False,
                    'error': result.stderr,
                    'return_code': result.returncode
                }
        
        except Exception as e:
            self.log_step("Mise Ã  jour systÃ¨me dÃ©tection", False, str(e))
            return {'success': False, 'error': str(e)}
    
    def step_3_restart_services(self) -> Dict:
        """Ã‰tape 3: RedÃ©marrage services"""
        logger.info("ğŸ”„ Ã‰TAPE 3: RedÃ©marrage services")
        
        try:
            # RedÃ©marrage frontend pour prise en compte nouvelles sÃ©ries
            cmd = ['sudo', 'supervisorctl', 'restart', 'frontend']
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                self.log_step("RedÃ©marrage services", True,
                             "Frontend redÃ©marrÃ© avec succÃ¨s")
                return {'success': True, 'output': result.stdout}
            
            else:
                self.log_step("RedÃ©marrage services", False,
                             f"Erreur redÃ©marrage: {result.stderr}")
                return {'success': False, 'error': result.stderr}
        
        except Exception as e:
            self.log_step("RedÃ©marrage services", False, str(e))
            return {'success': False, 'error': str(e)}
    
    def step_4_validate_integration(self) -> Dict:
        """Ã‰tape 4: Validation intÃ©gration"""
        logger.info("ğŸ§ª Ã‰TAPE 4: Validation intÃ©gration")
        
        try:
            # VÃ©rification fichiers gÃ©nÃ©rÃ©s
            js_file = Path('/app/frontend/src/data/extendedSeriesDatabase.js')
            json_file = Path('/app/backend/data/extended_series_database.json')
            
            if not js_file.exists():
                self.log_step("Validation intÃ©gration", False,
                             "Fichier JS manquant")
                return {'success': False, 'error': 'Fichier JS manquant'}
            
            if not json_file.exists():
                self.log_step("Validation intÃ©gration", False,
                             "Fichier JSON manquant")
                return {'success': False, 'error': 'Fichier JSON manquant'}
            
            # VÃ©rification contenu JS
            with open(js_file, 'r', encoding='utf-8') as f:
                js_content = f.read()
            
            if 'EXTENDED_SERIES_DATABASE' not in js_content:
                self.log_step("Validation intÃ©gration", False,
                             "Contenu JS invalide")
                return {'success': False, 'error': 'Contenu JS invalide'}
            
            # VÃ©rification contenu JSON
            with open(json_file, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
            
            if not isinstance(json_data, list) or len(json_data) == 0:
                self.log_step("Validation intÃ©gration", False,
                             "DonnÃ©es JSON invalides")
                return {'success': False, 'error': 'DonnÃ©es JSON invalides'}
            
            # Validation structure
            required_fields = ['name', 'authors', 'category', 'volumes']
            for series in json_data[:5]:  # VÃ©rification Ã©chantillon
                for field in required_fields:
                    if field not in series:
                        self.log_step("Validation intÃ©gration", False,
                                     f"Champ manquant: {field}")
                        return {'success': False, 'error': f'Champ manquant: {field}'}
            
            self.log_step("Validation intÃ©gration", True,
                         f"Fichiers validÃ©s: {len(json_data)} sÃ©ries")
            
            return {
                'success': True,
                'series_count': len(json_data),
                'js_file_size': js_file.stat().st_size,
                'json_file_size': json_file.stat().st_size
            }
        
        except Exception as e:
            self.log_step("Validation intÃ©gration", False, str(e))
            return {'success': False, 'error': str(e)}
    
    def step_5_generate_report(self, step_results: List[Dict]) -> Dict:
        """Ã‰tape 5: GÃ©nÃ©ration rapport final"""
        logger.info("ğŸ“Š Ã‰TAPE 5: GÃ©nÃ©ration rapport final")
        
        try:
            # Compilation statistiques
            total_series = self.pipeline_stats['series_added']
            total_updated = self.pipeline_stats['series_updated']
            duration = datetime.now() - self.pipeline_stats['start_time']
            
            # GÃ©nÃ©ration rapport
            report = f"""
ğŸ¯ RAPPORT PIPELINE AUTOMATISATION SÃ‰RIES OPEN LIBRARY
======================================================

ğŸ“Š RÃ‰SUMÃ‰ EXÃ‰CUTION
- Date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- DurÃ©e totale: {duration}
- Ã‰tapes complÃ©tÃ©es: {self.pipeline_stats['steps_completed']}/{self.pipeline_stats['total_steps']}
- Statut: {'âœ… SUCCÃˆS' if len(self.pipeline_stats['errors']) == 0 else 'âŒ ERREURS'}

ğŸ”¢ STATISTIQUES SÃ‰RIES
- Nouvelles sÃ©ries ajoutÃ©es: {total_series}
- SÃ©ries totales dans systÃ¨me: {total_updated}
- Doublons ignorÃ©s: {step_results[0].get('duplicates_skipped', 0) if step_results else 0}

ğŸ“‹ DÃ‰TAIL Ã‰TAPES
"""
            
            # DÃ©tail des Ã©tapes
            step_names = [
                "RÃ©cupÃ©ration sÃ©ries Open Library",
                "Mise Ã  jour systÃ¨me dÃ©tection",
                "RedÃ©marrage services",
                "Validation intÃ©gration",
                "GÃ©nÃ©ration rapport final"
            ]
            
            for i, (step_name, step_result) in enumerate(zip(step_names, step_results)):
                status = "âœ…" if step_result.get('success', False) else "âŒ"
                report += f"{i+1}. {status} {step_name}\n"
                
                if not step_result.get('success', False):
                    report += f"   Erreur: {step_result.get('error', 'Inconnue')}\n"
            
            # Erreurs
            if self.pipeline_stats['errors']:
                report += f"\nâŒ ERREURS RENCONTRÃ‰ES ({len(self.pipeline_stats['errors'])})\n"
                for error in self.pipeline_stats['errors']:
                    report += f"- {error}\n"
            
            # Prochaines Ã©tapes
            report += f"""
ğŸš€ PROCHAINES Ã‰TAPES
- Tester fonctionnalitÃ©s masquage intelligent
- VÃ©rifier dÃ©tection automatique sÃ©ries
- Surveiller logs dÃ©tection
- Planifier prochaine exÃ©cution automatisation

ğŸ“ FICHIERS GÃ‰NÃ‰RÃ‰S
- DonnÃ©es JSON: /app/backend/data/extended_series_database.json
- SystÃ¨me JS: /app/frontend/src/data/extendedSeriesDatabase.js
- Logs: /app/logs/
- Rapports: /app/reports/

âš¡ PERFORMANCE
- SÃ©ries par minute: {total_series / max(1, duration.total_seconds() / 60):.1f}
- EfficacitÃ©: {(total_series / max(1, total_series + step_results[0].get('duplicates_skipped', 0))) * 100:.1f}% (nouvelles/total)
"""
            
            # Sauvegarde rapport
            report_file = self.reports_dir / f"pipeline_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            self.log_step("GÃ©nÃ©ration rapport final", True,
                         f"Rapport sauvegardÃ©: {report_file}")
            
            return {
                'success': True,
                'report_file': str(report_file),
                'report_content': report
            }
        
        except Exception as e:
            self.log_step("GÃ©nÃ©ration rapport final", False, str(e))
            return {'success': False, 'error': str(e)}
    
    async def run_pipeline(self, mode: str = 'popular', limit: int = 50, test_only: bool = False) -> Dict:
        """ExÃ©cution pipeline complÃ¨te"""
        
        logger.info("ğŸš€ DÃ‰MARRAGE PIPELINE AUTOMATISATION SÃ‰RIES")
        logger.info(f"Mode: {mode}, Limit: {limit}, Test: {test_only}")
        
        step_results = []
        
        # Ã‰tape 1: RÃ©cupÃ©ration sÃ©ries
        if not test_only:
            result_1 = await self.step_1_fetch_series(mode, limit)
            step_results.append(result_1)
            
            if not result_1['success']:
                logger.error("âŒ Ã‰chec Ã©tape 1 - ArrÃªt pipeline")
                return {'success': False, 'error': 'Ã‰chec rÃ©cupÃ©ration sÃ©ries'}
        
        else:
            # Mode test - simulation
            self.log_step("RÃ©cupÃ©ration sÃ©ries Open Library (TEST)", True, "Mode test activÃ©")
            step_results.append({'success': True, 'test_mode': True})
        
        # Ã‰tape 2: Mise Ã  jour dÃ©tection
        result_2 = self.step_2_update_detection()
        step_results.append(result_2)
        
        if not result_2['success']:
            logger.error("âŒ Ã‰chec Ã©tape 2 - ArrÃªt pipeline")
            return {'success': False, 'error': 'Ã‰chec mise Ã  jour dÃ©tection'}
        
        # Ã‰tape 3: RedÃ©marrage services
        result_3 = self.step_3_restart_services()
        step_results.append(result_3)
        
        if not result_3['success']:
            logger.warning("âš ï¸ Ã‰chec Ã©tape 3 - Continuation pipeline")
        
        # Ã‰tape 4: Validation
        result_4 = self.step_4_validate_integration()
        step_results.append(result_4)
        
        if not result_4['success']:
            logger.error("âŒ Ã‰chec Ã©tape 4 - ArrÃªt pipeline")
            return {'success': False, 'error': 'Ã‰chec validation'}
        
        # Ã‰tape 5: Rapport
        result_5 = self.step_5_generate_report(step_results)
        step_results.append(result_5)
        
        # RÃ©sultat final
        success = all(r['success'] for r in step_results)
        
        if success:
            logger.info("ğŸ‰ PIPELINE TERMINÃ‰ AVEC SUCCÃˆS")
        else:
            logger.error("âŒ PIPELINE TERMINÃ‰ AVEC ERREURS")
        
        return {
            'success': success,
            'step_results': step_results,
            'total_duration': datetime.now() - self.pipeline_stats['start_time'],
            'series_added': self.pipeline_stats['series_added'],
            'series_updated': self.pipeline_stats['series_updated'],
            'errors': self.pipeline_stats['errors']
        }


async def main():
    """Fonction principale CLI"""
    parser = argparse.ArgumentParser(description='Pipeline automatisation sÃ©ries')
    parser.add_argument('--mode',
                       choices=['popular', 'authors', 'categories'],
                       default='popular',
                       help='Mode de rÃ©cupÃ©ration')
    parser.add_argument('--limit',
                       type=int,
                       default=50,
                       help='Nombre maximum de sÃ©ries')
    parser.add_argument('--quick',
                       action='store_true',
                       help='ExÃ©cution rapide (limit=20)')
    parser.add_argument('--full',
                       action='store_true',
                       help='ExÃ©cution complÃ¨te (limit=100)')
    parser.add_argument('--test-only',
                       action='store_true',
                       help='Mode test sans rÃ©cupÃ©ration')
    
    args = parser.parse_args()
    
    # Ajustement limite selon mode
    if args.quick:
        args.limit = 20
    elif args.full:
        args.limit = 100
    
    # CrÃ©ation pipeline
    pipeline = SeriesAutomationPipeline()
    
    # ExÃ©cution
    result = await pipeline.run_pipeline(
        mode=args.mode,
        limit=args.limit,
        test_only=args.test_only
    )
    
    # Affichage rÃ©sultat
    if result['success']:
        print(f"\nğŸ‰ PIPELINE RÃ‰USSI")
        print(f"ğŸ“Š SÃ©ries ajoutÃ©es: {result['series_added']}")
        print(f"ğŸ”„ SÃ©ries dans systÃ¨me: {result['series_updated']}")
        print(f"â±ï¸ DurÃ©e: {result['total_duration']}")
        
        if result['step_results'] and result['step_results'][-1]['success']:
            print(f"ğŸ“‹ Rapport: {result['step_results'][-1]['report_file']}")
    
    else:
        print(f"\nâŒ PIPELINE Ã‰CHOUÃ‰")
        print(f"ğŸš¨ Erreurs: {len(result['errors'])}")
        for error in result['errors']:
            print(f"   - {error}")
        
        return 1
    
    return 0


if __name__ == "__main__":
    exit(asyncio.run(main()))