"""
Routes API Wikidata pour BOOKTIME
Endpoints pour s√©ries, livres et auteurs avec donn√©es structur√©es
"""

from fastapi import APIRouter, HTTPException, Query
from typing import Optional
import logging

from .service import wikidata_service
from .models import (
    WikidataAuthorResponse, WikidataSeriesResponse, WikidataSeriesSearchResponse,
    WikidataTestResponse
)

router = APIRouter(prefix="/api/wikidata", tags=["wikidata"])

logger = logging.getLogger(__name__)

@router.get("/author/{author_name}/series", response_model=WikidataAuthorResponse)
async def get_author_series(author_name: str):
    """
    R√©cup√®re les s√©ries ET livres individuels d'un auteur depuis Wikidata
    Donn√©es structur√©es avec m√©tadonn√©es enrichies - VERSION COMPL√àTE
    """
    try:
        logger.info(f"üîç Recherche ≈ìuvres compl√®tes Wikidata pour: {author_name}")
        
        # R√©cup√©rer les s√©ries de l'auteur (VERSION √âLARGIE)
        series_result = await wikidata_service.get_author_series(author_name)
        
        # R√©cup√©rer les livres individuels de l'auteur (NOUVEAU)
        individual_books = await wikidata_service.get_author_individual_books(author_name)
        
        # Combiner les r√©sultats
        total_items = len(series_result.series) + len(individual_books) if series_result.found else len(individual_books)
        
        if total_items > 0:
            logger.info(f"‚úÖ {len(series_result.series)} s√©ries + {len(individual_books)} livres individuels trouv√©s pour {author_name}")
            
            # Convertir les livres individuels au format attendu
            individual_books_formatted = []
            for book in individual_books:
                individual_books_formatted.append({
                    "title": book.title,
                    "publication_date": book.publication_date,
                    "genre": book.genre,
                    "isbn": book.isbn,
                    "publisher": book.publisher,
                    "description": book.description,
                    "book_type": getattr(book, 'book_type', 'literary work'),
                    "source": "wikidata"
                })
            
            return {
                "found": True,
                "source": "wikidata",
                "query_time": series_result.query_time,
                "results_count": total_items,
                "series": series_result.series,
                "individual_books": individual_books_formatted,
                "total_series": len(series_result.series),
                "total_individual_books": len(individual_books)
            }
        else:
            logger.warning(f"‚ùå Aucune ≈ìuvre trouv√©e pour {author_name}")
            return {
                "found": False,
                "source": "wikidata",
                "query_time": series_result.query_time,
                "results_count": 0,
                "series": [],
                "individual_books": [],
                "total_series": 0,
                "total_individual_books": 0
            }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des ≈ìuvres pour {author_name}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la r√©cup√©ration des ≈ìuvres: {str(e)}"
        )

@router.get("/series/{series_id}/books", response_model=WikidataSeriesResponse)
async def get_series_books(series_id: str):
    """
    R√©cup√®re les livres d'une s√©rie depuis Wikidata
    Donn√©es structur√©es avec volumes, dates et m√©tadonn√©es
    """
    try:
        logger.info(f"üìö Recherche livres s√©rie Wikidata: {series_id}")
        
        # Valider l'ID Wikidata
        if not series_id.startswith('Q'):
            raise HTTPException(
                status_code=400,
                detail="ID s√©rie invalide. Doit commencer par 'Q' (ex: Q8337)"
            )
        
        # R√©cup√©rer les livres de la s√©rie
        result = await wikidata_service.get_series_books(series_id)
        
        if result.found:
            logger.info(f"‚úÖ {result.results_count} livres trouv√©s pour s√©rie {series_id}")
        else:
            logger.warning(f"‚ùå Aucun livre trouv√© pour s√©rie {series_id}")
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des livres pour s√©rie {series_id}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la r√©cup√©ration des livres: {str(e)}"
        )

@router.get("/series/{series_id}/info")
async def get_series_info(series_id: str):
    """
    R√©cup√®re les informations compl√®tes d'une s√©rie
    M√©tadonn√©es d√©taill√©es et statistiques
    """
    try:
        logger.info(f"‚ÑπÔ∏è Informations s√©rie Wikidata: {series_id}")
        
        # Valider l'ID Wikidata
        if not series_id.startswith('Q'):
            raise HTTPException(
                status_code=400,
                detail="ID s√©rie invalide. Doit commencer par 'Q' (ex: Q8337)"
            )
        
        # R√©cup√©rer les informations et livres en parall√®le
        books_result = await wikidata_service.get_series_books(series_id)
        
        if not books_result.found:
            return {
                "found": False,
                "message": f"S√©rie {series_id} non trouv√©e"
            }
        
        # Calculer les statistiques
        books = books_result.books
        volumes_count = len(books)
        
        # Extraire les ann√©es de publication
        years = [book.publication_date for book in books if book.publication_date]
        start_year = min(years) if years else None
        latest_year = max(years) if years else None
        
        # Extraire les genres
        genres = list(set([book.genre for book in books if book.genre]))
        
        # Construire la r√©ponse
        series_info = {
            "found": True,
            "series_id": series_id,
            "volumes_count": volumes_count,
            "start_year": start_year,
            "latest_year": latest_year,
            "genres": genres,
            "books": books,
            "query_time": books_result.query_time
        }
        
        logger.info(f"‚úÖ Informations s√©rie {series_id}: {volumes_count} volumes")
        return series_info
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des informations pour s√©rie {series_id}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la r√©cup√©ration des informations: {str(e)}"
        )

@router.get("/search/series", response_model=WikidataSeriesSearchResponse)
async def search_series(
    q: str = Query(..., description="Terme de recherche"),
    limit: int = Query(20, ge=1, le=50, description="Nombre maximum de r√©sultats")
):
    """
    Recherche des s√©ries par nom
    Recherche dans les entit√©s s√©ries de Wikidata
    """
    try:
        logger.info(f"üîç Recherche s√©ries Wikidata: '{q}' (limite: {limit})")
        
        # Rechercher les s√©ries
        result = await wikidata_service.search_series(q, limit)
        
        if result.found:
            logger.info(f"‚úÖ {result.results_count} s√©ries trouv√©es pour '{q}'")
        else:
            logger.warning(f"‚ùå Aucune s√©rie trouv√©e pour '{q}'")
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la recherche de s√©ries '{q}': {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la recherche: {str(e)}"
        )

@router.get("/author/{author_name}/info")
async def get_author_info(author_name: str):
    """
    R√©cup√®re les informations d√©taill√©es d'un auteur
    M√©tadonn√©es biographiques et statistiques
    """
    try:
        logger.info(f"üë§ Informations auteur Wikidata: {author_name}")
        
        # R√©cup√©rer les informations de l'auteur
        author_info = await wikidata_service.get_author_info(author_name)
        
        if not author_info:
            return {
                "found": False,
                "message": f"Auteur '{author_name}' non trouv√© sur Wikidata"
            }
        
        # R√©cup√©rer √©galement les s√©ries
        series_result = await wikidata_service.get_author_series(author_name)
        
        # Enrichir avec les comptages
        author_info.series_count = len(series_result.series) if series_result.found else 0
        
        return {
            "found": True,
            "source": "wikidata",
            "author": author_info,
            "series": series_result.series if series_result.found else []
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des informations pour {author_name}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la r√©cup√©ration des informations: {str(e)}"
        )

@router.get("/test/{author_name}", response_model=WikidataTestResponse)
async def test_wikidata_connection(author_name: str = "rowling"):
    """
    Test de connexion et requ√™te Wikidata
    Endpoint de d√©veloppement pour v√©rifier le service
    """
    try:
        logger.info(f"üß™ Test connexion Wikidata avec: {author_name}")
        
        # Tester la connexion
        test_result = await wikidata_service.test_connection(author_name)
        
        return WikidataTestResponse(
            success=test_result.get("success", False),
            query=test_result.get("query", ""),
            results=test_result.get("results", []),
            processed_results=test_result.get("processed_results", {}),
            execution_time=test_result.get("execution_time", 0.0),
            error=test_result.get("error")
        )
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du test Wikidata: {str(e)}")
        return WikidataTestResponse(
            success=False,
            query="",
            results=[],
            processed_results={},
            execution_time=0.0,
            error=str(e)
        )

@router.get("/author/{author_name}/works")
async def get_author_works(author_name: str):
    """
    DEPRECATED: Utiliser /author/{author_name}/series √† la place
    R√©cup√®re les s√©ries ET les livres individuels d'un auteur depuis Wikidata
    """
    return await get_author_series(author_name)

@router.get("/stats")
async def get_wikidata_stats():
    """
    Statistiques du service Wikidata
    Cache, performance et utilisation
    """
    try:
        cache_stats = {
            "cache_size": len(wikidata_service.cache),
            "cache_ttl": wikidata_service.cache_ttl,
            "request_delay": wikidata_service.request_delay,
            "last_request": wikidata_service.last_request_time
        }
        
        return {
            "service_status": "operational",
            "sparql_endpoint": wikidata_service.sparql_endpoint,
            "cache_stats": cache_stats,
            "features": [
                "Series detection",
                "Author information",
                "Book metadata",
                "SPARQL queries",
                "Intelligent caching"
            ]
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des statistiques: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la r√©cup√©ration des statistiques: {str(e)}"
        )