#!/usr/bin/env python3
"""
ğŸ” ULTRA HARVEST NICHES ULTRA-SPÃ‰CIALISÃ‰ES 70% - SESSION 81.26B
Script pour explorer des micro-niches trÃ¨s spÃ©cialisÃ©es avec seuil 70%
Focus sur des domaines ultra-techniques et spÃ©cialisÃ©s
"""

import asyncio
import aiohttp
import json
import random
import time
from datetime import datetime
from pathlib import Path
import logging
import sqlite3
import re

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('UltraHarvestMicroNiches')

class MicroNichesHarvest:
    """Ultra Harvest pour micro-niches ultra-spÃ©cialisÃ©es"""
    
    def __init__(self):
        self.new_series_found = []
        self.books_analyzed = 0
        self.api_calls = 0
        self.start_time = datetime.now()
        self.confidence_threshold = 70
        
        # Charger base existante
        self.existing_series = set()
        self._load_existing_series()
        
        # Patterns ultra-spÃ©cialisÃ©s
        self._init_micro_patterns()
    
    def _load_existing_series(self):
        """Charger sÃ©ries existantes"""
        series_path = Path('/app/backend/data/extended_series_database.json')
        if series_path.exists():
            with open(series_path, 'r') as f:
                series_data = json.load(f)
                for series in series_data:
                    name = series.get('name', '').lower()
                    if name:
                        self.existing_series.add(name)
        logger.info(f"âœ… {len(self.existing_series)} sÃ©ries existantes chargÃ©es")
    
    def _init_micro_patterns(self):
        """Patterns pour micro-niches ultra-spÃ©cialisÃ©es"""
        self.micro_patterns = [
            # Professions ultra-spÃ©cialisÃ©es
            r'(.+?)\s+(?:certification|cert)\s+(?:guide|book)\s*(\d+)',
            r'(.+?)\s+(?:professional|pro)\s+(?:handbook|manual)\s*(\d+)',
            r'(.+?)\s+(?:training|formation)\s+(?:course|cours)\s*(\d+)',
            
            # Hobbies ultra-spÃ©cialisÃ©s
            r'(.+?)\s+(?:collecting|collection)\s+(?:guide|handbook)\s*(\d+)',
            r'(.+?)\s+(?:modeling|models)\s+(?:book|guide)\s*(\d+)',
            r'(.+?)\s+(?:restoration|repair)\s+(?:manual|guide)\s*(\d+)',
            
            # RÃ©gions gÃ©ographiques spÃ©cifiques
            r'(.+?)\s+(?:regional|local)\s+(?:guide|handbook)\s*(\d+)',
            r'(.+?)\s+(?:provincial|state)\s+(?:series|collection)\s*(\d+)',
            r'(.+?)\s+(?:county|district)\s+(?:history|guide)\s*(\d+)',
            
            # Sciences ultra-spÃ©cialisÃ©es
            r'(.+?)\s+(?:microscopy|microsc)\s+(?:handbook|guide)\s*(\d+)',
            r'(.+?)\s+(?:spectroscopy|spectr)\s+(?:manual|book)\s*(\d+)',
            r'(.+?)\s+(?:crystallography|crystal)\s+(?:guide|handbook)\s*(\d+)',
            
            # Arts martiaux et sports spÃ©cialisÃ©s
            r'(.+?)\s+(?:martial arts|arts martiaux)\s+(?:series|guide)\s*(\d+)',
            r'(.+?)\s+(?:aikido|judo|karate)\s+(?:book|manual)\s*(\d+)',
            r'(.+?)\s+(?:archery|tir Ã  l\'arc)\s+(?:guide|handbook)\s*(\d+)',
            
            # Musique ultra-spÃ©cialisÃ©e
            r'(.+?)\s+(?:sheet music|partition)\s+(?:book|collection)\s*(\d+)',
            r'(.+?)\s+(?:instrument|musical)\s+(?:method|mÃ©thode)\s*(\d+)',
            r'(.+?)\s+(?:composition|theory)\s+(?:book|guide)\s*(\d+)',
            
            # Langues rares
            r'(.+?)\s+(?:language|langue)\s+(?:course|cours)\s*(?:book|livre)\s*(\d+)',
            r'(.+?)\s+(?:dictionary|dictionnaire)\s*(?:volume|tome)\s*(\d+)',
            r'(.+?)\s+(?:grammar|grammaire)\s+(?:book|livre)\s*(\d+)',
            
            # Collectibles et antiquitÃ©s
            r'(.+?)\s+(?:antique|antiques)\s+(?:guide|collector)\s*(\d+)',
            r'(.+?)\s+(?:vintage|collectible)\s+(?:book|guide)\s*(\d+)',
            r'(.+?)\s+(?:price guide|guide prix)\s*(\d+)',
            
            # SantÃ© alternative
            r'(.+?)\s+(?:herbal|herbs)\s+(?:medicine|guide)\s*(\d+)',
            r'(.+?)\s+(?:homeopathy|homeo)\s+(?:handbook|guide)\s*(\d+)',
            r'(.+?)\s+(?:acupuncture|energy)\s+(?:healing|guide)\s*(\d+)',
            
            # Industries spÃ©cialisÃ©es
            r'(.+?)\s+(?:aerospace|aviation)\s+(?:handbook|manual)\s*(\d+)',
            r'(.+?)\s+(?:maritime|marine)\s+(?:guide|handbook)\s*(\d+)',
            r'(.+?)\s+(?:mining|petroleum)\s+(?:manual|guide)\s*(\d+)',
            
            # Technologies Ã©mergentes
            r'(.+?)\s+(?:blockchain|crypto)\s+(?:guide|handbook)\s*(\d+)',
            r'(.+?)\s+(?:ai|artificial intelligence)\s+(?:book|guide)\s*(\d+)',
            r'(.+?)\s+(?:iot|internet of things)\s+(?:handbook|guide)\s*(\d+)',
        ]
    
    def _generate_micro_niche_queries(self):
        """GÃ©nÃ©rer requÃªtes pour micro-niches ultra-spÃ©cialisÃ©es"""
        return [
            # Professions ultra-spÃ©cialisÃ©es
            "sommelier certification book", "genealogy research guide", "private investigator manual",
            "funeral director handbook", "locksmith training book", "elevator technician guide",
            "court reporter certification", "water well drilling manual", "chimney sweep handbook",
            "piano tuner guide book", "clockmaker restoration manual", "taxidermy guide book",
            
            # Hobbies ultra-spÃ©cialisÃ©s  
            "vintage radio collecting", "meteorite hunting guide", "bottle cap collecting book",
            "postcard collecting handbook", "coin grading guide book", "stamp catalog series",
            "model railroad scenery book", "rc helicopter manual", "slot car racing guide",
            "dollhouse miniatures book", "origami advanced techniques", "paper airplane design",
            
            # Sports et activitÃ©s nichÃ©es
            "falconry training manual", "beekeeping seasonal guide", "mushroom foraging book",
            "geocaching adventure guide", "metal detecting handbook", "fossil hunting guide",
            "astronomy observation log", "bird watching field guide", "wildflower identification",
            "tree identification guide", "butterfly field guide", "mineral identification",
            
            # Arts et crafts ultra-spÃ©cialisÃ©s
            "bookbinding traditional methods", "calligraphy brush techniques", "stained glass patterns",
            "chain mail making guide", "blacksmithing projects book", "leather working patterns",
            "soap making advanced", "candle making techniques", "pewter casting manual",
            "glass blowing guide", "pottery wheel throwing", "silk painting techniques",
            
            # Cultures et traditions
            "bagpipe music collection", "dulcimer playing guide", "hurdy gurdy manual",
            "concertina instruction book", "morris dancing guide", "folk dance collection",
            "traditional crafts revival", "heritage skills manual", "ancestral techniques",
            
            # Sciences appliquÃ©es nichÃ©es
            "beehive inspection guide", "soil analysis handbook", "water quality testing",
            "air quality monitoring", "noise level measurement", "electromagnetic fields guide",
            "radiation detection manual", "chemical analysis guide", "microscopy techniques",
            
            # RÃ©paration ultra-spÃ©cialisÃ©e
            "antique clock repair", "vintage camera restoration", "tube radio service",
            "mechanical watch repair", "fountain pen restoration", "typewriter maintenance",
            "player piano restoration", "grandfather clock repair", "music box restoration",
            
            # Collections spÃ©cialisÃ©es
            "military button collecting", "thimble collecting guide", "spoon collecting handbook",
            "key collecting reference", "matchbook collecting", "tobacco card collecting",
            "vintage toy collecting", "advertising memorabilia", "railroad memorabilia guide",
            
            # RÃ©gions gÃ©ographiques ultra-spÃ©cifiques
            "appalachian folklore collection", "pacific northwest mushrooms", "desert survival manual",
            "arctic exploration guide", "tropical plant identification", "coastal ecology handbook",
            "mountain climbing routes", "cave exploration guide", "swamp navigation manual",
            
            # Langues et cultures rares
            "gaelic language course", "sanskrit learning guide", "ancient greek primer",
            "latin conversation book", "esperanto grammar book", "sign language regional",
            "native american languages", "polynesian culture guide", "celtic mythology collection",
            
            # MÃ©decines alternatives
            "crystal healing handbook", "essential oils guide", "reflexology manual",
            "reiki healing methods", "chakra balancing guide", "feng shui home design",
            "ayurveda cooking book", "traditional chinese medicine", "naturopathy handbook",
            
            # Technologies ultra-spÃ©cialisÃ©es
            "cnc machining manual", "3d printing advanced", "laser cutting guide",
            "vacuum tube electronics", "ham radio construction", "antenna design book",
            "microcontroller projects", "sensor network design", "embedded systems guide",
            
            # Industries de niche
            "beekeeping commercial", "aquaculture systems", "greenhouse management",
            "hydroponics advanced", "permaculture design", "sustainable farming",
            "organic certification", "biodynamic agriculture", "regenerative farming",
            
            # Arts martiaux spÃ©cialisÃ©s
            "kendo practice guide", "iaido sword training", "kyudo archery manual",
            "capoeira movement book", "escrima stick fighting", "wing chun techniques",
            "tai chi advanced forms", "qigong energy work", "aikido philosophy book",
            
            # Collectibles vintage
            "vintage electronics repair", "antique furniture restoration", "classic car maintenance",
            "vintage clothing care", "retro gaming repair", "old book conservation",
            "vinyl record care", "antique jewelry guide", "vintage watch collecting"
        ]
    
    def _detect_micro_series(self, title, authors, subjects):
        """DÃ©tecter sÃ©ries dans micro-niches"""
        if not title:
            return None
            
        title_lower = title.lower()
        
        # Patterns spÃ©cialisÃ©s
        for pattern in self.micro_patterns:
            match = re.search(pattern, title_lower)
            if match:
                series_name = match.group(1).strip()
                volume_num = match.group(2) if len(match.groups()) > 1 else "1"
                
                if len(series_name) >= 3 and series_name not in self.existing_series:
                    confidence = self._calculate_micro_confidence(series_name, authors, subjects, title)
                    if confidence >= self.confidence_threshold:
                        return {
                            'name': series_name.title(),
                            'volume': volume_num,
                            'confidence': confidence,
                            'detection_method': 'micro_niche_patterns',
                            'original_title': title
                        }
        
        return None
    
    def _calculate_micro_confidence(self, series_name, authors, subjects, original_title):
        """Calculer confiance pour micro-niches"""
        confidence = 70  # Base
        
        # Mots-clÃ©s micro-niches
        micro_keywords = [
            'certification', 'professional', 'handbook', 'manual', 'guide',
            'collecting', 'restoration', 'repair', 'traditional', 'specialized',
            'advanced', 'techniques', 'methods', 'training', 'course'
        ]
        
        title_lower = original_title.lower()
        subjects_text = ' '.join(subjects).lower() if subjects else ''
        
        for keyword in micro_keywords:
            if keyword in title_lower or keyword in subjects_text:
                confidence += 3
        
        # Bonus pour numÃ©rotation
        if re.search(r'\b(?:volume|book|part|level)\s+\d+', title_lower):
            confidence += 10
        
        # Bonus pour sÃ©ries techniques
        if any(word in title_lower for word in ['series', 'collection', 'set']):
            confidence += 5
        
        return min(confidence, 100)
    
    async def _search_micro_niche(self, session, query, limit=25):
        """Rechercher dans micro-niche"""
        url = "https://openlibrary.org/search.json"
        params = {
            'q': query,
            'limit': limit,
            'fields': 'key,title,author_name,subject,first_publish_year'
        }
        
        try:
            await asyncio.sleep(random.uniform(0.4, 0.8))
            
            async with session.get(url, params=params, timeout=30) as response:
                if response.status == 200:
                    data = await response.json()
                    self.api_calls += 1
                    return data.get('docs', [])
                else:
                    return []
                    
        except Exception as e:
            logger.error(f"Error: {str(e)}")
            return []
    
    async def explore_micro_niches(self, max_queries=100):
        """Explorer micro-niches intensivement"""
        logger.info("ğŸ” DÃ‰BUT EXPLORATION MICRO-NICHES ULTRA-SPÃ‰CIALISÃ‰ES")
        
        queries = self._generate_micro_niche_queries()
        discoveries = []
        
        async with aiohttp.ClientSession() as session:
            for i, query in enumerate(queries[:max_queries]):
                if i % 10 == 0:
                    logger.info(f"ğŸ” Progression: {i}/{min(max_queries, len(queries))} niches explorÃ©es")
                
                books = await self._search_micro_niche(session, query, 25)
                
                for book in books:
                    self.books_analyzed += 1
                    
                    title = book.get('title', '')
                    authors = book.get('author_name', [])
                    subjects = book.get('subject', [])
                    
                    # Exclure acadÃ©mique basique
                    if any(x in title.lower() for x in ['journal of', 'proceedings', 'thesis']):
                        continue
                    
                    series_info = self._detect_micro_series(title, authors, subjects)
                    if series_info:
                        series_key = series_info['name'].lower()
                        if series_key not in self.existing_series:
                            discoveries.append(series_info)
                            self.existing_series.add(series_key)
                            logger.info(f"ğŸ†• Micro-niche: {series_info['name']} (conf: {series_info['confidence']}%)")
                
                # Limite sÃ©curisÃ©e
                if self.api_calls >= 150:
                    logger.warning("âš ï¸ Limite API atteinte")
                    break
        
        self.new_series_found = discoveries
        return discoveries
    
    def _save_micro_discoveries(self):
        """Sauvegarder dÃ©couvertes micro-niches"""
        if not self.new_series_found:
            logger.info("âŒ Aucune nouvelle sÃ©rie micro-niche trouvÃ©e")
            return
        
        # Charger base
        series_path = Path('/app/backend/data/extended_series_database.json')
        with open(series_path, 'r') as f:
            existing_series = json.load(f)
        
        # CrÃ©er nouvelles entrÃ©es
        new_entries = []
        for discovery in self.new_series_found:
            series_entry = {
                "name": discovery['name'],
                "authors": ["Specialist"],
                "category": "roman",  # Sera affinÃ©
                "volumes": 1,
                "keywords": [discovery['name'].lower(), "micro niche", "specialized"],
                "variations": [discovery['name'], discovery['name'].lower()],
                "languages": ["en", "fr"],
                "description": f"SÃ©rie micro-niche ultra-spÃ©cialisÃ©e (confiance: {discovery['confidence']}%)",
                "confidence_score": discovery['confidence'],
                "detection_method": discovery['detection_method'],
                "source": "ultra_harvest_micro_niches_session_81_26b",
                "first_published": 2020,
                "status": "active",
                "subjects": ["micro niche", "specialized", "professional"],
                "patterns": {
                    "title_patterns": [discovery['name']],
                    "exclude_patterns": ["anthology", "journal"]
                }
            }
            new_entries.append(series_entry)
        
        # Backup et sauvegarde
        backup_path = series_path.parent / f"extended_series_database_backup_micro_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        import shutil
        shutil.copy2(series_path, backup_path)
        
        existing_series.extend(new_entries)
        
        with open(series_path, 'w', encoding='utf-8') as f:
            json.dump(existing_series, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… {len(new_entries)} nouvelles sÃ©ries micro-niches ajoutÃ©es")
        logger.info(f"ğŸ’¾ Backup: {backup_path.name}")

async def main():
    """Exploration micro-niches principale"""
    harvester = MicroNichesHarvest()
    
    logger.info("ğŸ” ULTRA HARVEST MICRO-NICHES - SESSION 81.26B")
    logger.info(f"ğŸ“Š Base: {len(harvester.existing_series)} sÃ©ries")
    
    # Explorer intensivement
    discoveries = await harvester.explore_micro_niches(max_queries=80)
    
    # Sauvegarder
    harvester._save_micro_discoveries()
    
    # RÃ©sumÃ©
    duration = datetime.now() - harvester.start_time
    logger.info("ğŸ¯ MICRO-NICHES EXPLORATION TERMINÃ‰E")
    logger.info(f"â±ï¸ DurÃ©e: {duration}")
    logger.info(f"ğŸ“š Livres analysÃ©s: {harvester.books_analyzed}")
    logger.info(f"ğŸ” API calls: {harvester.api_calls}")
    logger.info(f"ğŸ†• Nouvelles sÃ©ries: {len(discoveries)}")
    
    if discoveries:
        logger.info("ğŸŒŸ TOP MICRO-NICHES:")
        for i, d in enumerate(discoveries[:10], 1):
            logger.info(f"  {i}. {d['name']} (conf: {d['confidence']}%)")

if __name__ == "__main__":
    asyncio.run(main())